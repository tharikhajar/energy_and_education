{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Energy Matrix & Education\n",
    "\n",
    "### In this notebook we will clean and prepare the data for our Tableau Visualization. See below the datasets that we will use:\n",
    "\n",
    "- [Energy consumption by source, country and year](https://github.com/owid/energy-data).\n",
    "- [Education metrics & total population by country and year](http://hdr.undp.org/en/data).\n",
    "- [Country attributes to allow for aggregation (e.g. by continent)](https://github.com/datasets/country-codes).\n",
    "\n",
    "The energy data is already structured in a way close to what we need(courtesy of Our World in Data), while the education metrics are fragmented, so the latter will require more work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Energy Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This Dataset has more data than we need. There are 3 steps we will take here to prepare the data for further use\n",
    "\n",
    "- Remove unwanted fields. We want to keep the dimensions (Country, Country Code and Year) and the measures associated with the total consumption by a given country in a given year\n",
    "- There are rows that holds data for countries aggregates, such as \"South America\". If we keep it, we will end up duplicating the consumption amounts for south american countries when aggregating\n",
    "- We will also rename the measures related to each energy source now, as it is more convinient to do so before unpivoting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import copy\n",
    "\n",
    "# Keeping original dataset with another name as we will fetch some values from this later on\n",
    "df_energy_import = pd.read_csv('../Datasets\\energy_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First, we will slice the dataframe column-wise, so we keep only the fields that we will use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>iso_code</th>\n",
       "      <th>country</th>\n",
       "      <th>year</th>\n",
       "      <th>biofuel_share_energy</th>\n",
       "      <th>coal_share_energy</th>\n",
       "      <th>fossil_share_energy</th>\n",
       "      <th>gas_share_energy</th>\n",
       "      <th>hydro_share_energy</th>\n",
       "      <th>low_carbon_share_energy</th>\n",
       "      <th>nuclear_share_energy</th>\n",
       "      <th>oil_share_energy</th>\n",
       "      <th>other_renewables_share_energy</th>\n",
       "      <th>renewables_share_energy</th>\n",
       "      <th>solar_share_energy</th>\n",
       "      <th>wind_share_energy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AFG</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>1900</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AFG</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>1901</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AFG</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>1902</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AFG</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>1903</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AFG</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>1904</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  iso_code      country  year  biofuel_share_energy  coal_share_energy  \\\n",
       "0      AFG  Afghanistan  1900                   NaN                NaN   \n",
       "1      AFG  Afghanistan  1901                   NaN                NaN   \n",
       "2      AFG  Afghanistan  1902                   NaN                NaN   \n",
       "3      AFG  Afghanistan  1903                   NaN                NaN   \n",
       "4      AFG  Afghanistan  1904                   NaN                NaN   \n",
       "\n",
       "   fossil_share_energy  gas_share_energy  hydro_share_energy  \\\n",
       "0                  NaN               NaN                 NaN   \n",
       "1                  NaN               NaN                 NaN   \n",
       "2                  NaN               NaN                 NaN   \n",
       "3                  NaN               NaN                 NaN   \n",
       "4                  NaN               NaN                 NaN   \n",
       "\n",
       "   low_carbon_share_energy  nuclear_share_energy  oil_share_energy  \\\n",
       "0                      NaN                   NaN               NaN   \n",
       "1                      NaN                   NaN               NaN   \n",
       "2                      NaN                   NaN               NaN   \n",
       "3                      NaN                   NaN               NaN   \n",
       "4                      NaN                   NaN               NaN   \n",
       "\n",
       "   other_renewables_share_energy  renewables_share_energy  solar_share_energy  \\\n",
       "0                            NaN                      NaN                 NaN   \n",
       "1                            NaN                      NaN                 NaN   \n",
       "2                            NaN                      NaN                 NaN   \n",
       "3                            NaN                      NaN                 NaN   \n",
       "4                            NaN                      NaN                 NaN   \n",
       "\n",
       "   wind_share_energy  \n",
       "0                NaN  \n",
       "1                NaN  \n",
       "2                NaN  \n",
       "3                NaN  \n",
       "4                NaN  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# As the dataset has a lot of columns, it is good to start finding the \n",
    "# fields we want to keep by a common word in their names, if possible\n",
    "dim_cols = ['iso_code', 'country', 'year']\n",
    "measure_cols = [col for col in df_energy_import.columns if 'share_energy' in col]\n",
    "cols_to_keep = copy.copy(dim_cols)\n",
    "cols_to_keep.extend(measure_cols)\n",
    "\n",
    "# Dropping unwanted fields\n",
    "df_energy = df_energy_import[cols_to_keep]\n",
    "\n",
    "df_energy.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now, we will slice it based on row values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# As we only have education data from 1990 onwards, we will filter this accordingly\n",
    "# df_energy = df_energy[df_energy['year'] >= 1990]\n",
    "\n",
    "# As we have many aggregates of countries\n",
    "# We need to drop them as to not duplicate data & keep the analysis in terms of countries\n",
    "entities_to_drop = [\n",
    "    'World', 'Africa', 'Asia Pacific',\n",
    "    'CIS', 'Central America', 'Eastern Africa',\n",
    "    'Europe', 'Europe (other)', 'Middle Africa',\n",
    "    'Middle East', 'Netherlands Antilles', 'North America',\n",
    "    'OPEC', 'Other Asia & Pacific', 'Other CIS', \n",
    "    'Other Caribbean', 'Other Middle East', 'Other Northern Africa',\n",
    "    'Other South America', 'Other Southern Africa', 'South & Central America',\n",
    "    'South Africa', 'Western Africa', 'Western Sahara'\n",
    "    ]\n",
    "\n",
    "df_energy = df_energy[~df_energy['country'].isin(entities_to_drop)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To build the visualizations that we are aiming to in Tableau, we will need this data in long format, so we will unpivot it below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will rename the fields to how we want them to be displayed in the report view\n",
    "# If we intended to keep the measures as fields, we could rename them in Tableau, but as\n",
    "# we are unpivoting this (putting measure fields in one attribute field) it is better to do it now\n",
    "measure_cols = [\n",
    "    'Biofuels',\n",
    "    'Coal',\n",
    "    'Fossil Fuels',\n",
    "    'Natural Gas',\n",
    "    'Hydro',\n",
    "    'Low Carbon',\n",
    "    'Nuclear',\n",
    "    'Oil',\n",
    "    'Other Renewables',\n",
    "    'Renewables',\n",
    "    'Solar',\n",
    "    'Wind'\n",
    "    ]\n",
    "\n",
    "renamed_cols =  copy.copy(dim_cols)\n",
    "renamed_cols.extend(measure_cols)\n",
    "df_energy.columns = renamed_cols\n",
    "\n",
    "# In order to be able to measure correlation in Tableau, we will need unpivoted data\n",
    "df_energy = df_energy.melt(\n",
    "    id_vars=dim_cols, value_vars=measure_cols,\n",
    "    var_name='energy_source', value_name='share'\n",
    ")\n",
    "\n",
    "df_energy = df_energy[~df_energy['share'].isna()].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finally, we will bring in two additional measures from the original original dataset and countries attributes from dim country table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_energy_glb_metrics = df_energy_import[['iso_code', 'year', 'primary_energy_consumption', 'population']]\n",
    "df_energy = df_energy.merge(df_energy_glb_metrics, on=['iso_code', 'year'], how='left')\n",
    "\n",
    "df_countries = pd.read_csv('../Datasets\\dim_country.csv')\n",
    "df_countries = df_countries[[\n",
    "    'ISO3166-1-Alpha-3', 'CLDR display name', 'Continent',\n",
    "    'Region Name', 'Sub-region Name', 'Developed / Developing Countries'\n",
    "    ]]\n",
    "\n",
    "df_countries.columns = ['iso_code', 'country', 'continent', 'region name',\n",
    "       'sub-region_name', 'developed_developing']\n",
    "\n",
    "df_energy = df_energy.merge(df_countries, on='iso_code', how='left', suffixes=('', '_drop'))\n",
    "\n",
    "df_energy.drop(axis=1, columns='country_drop', inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_energy.to_csv('..\\Datasets/energy_date_long.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Education Data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we will need some more complex data cleaning & transformation.\n",
    "\n",
    "Some countries names differ from these datasets and the country attribute table that we are using. This is not an issue for the energy dataset as it contains countries iso codes.\n",
    "\n",
    "For that reason, I've created a mapping table to match the education datasets to the country dim table.\n",
    "We will leverage that here to filter out rows that contains data for countries aggregates instead of doing by hand (as was done in the energy dataset) considering we already have a list of all countries contained in this datasets.\n",
    "\n",
    "Additionally, it comes with bank columns between each year column. We are filtering that out by specifying the fields we wanna keep on importing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# We will use a list of all unique contry names contained in the UN education datasets\n",
    "# to filter out unwanted rows\n",
    "df_country_map = pd.read_csv('..\\Datasets/un_to_iso_mapping.csv', encoding='latin 1')\n",
    "un_countries_list = df_country_map['UN_Country'][~df_country_map['UN_Country'].isna()]\n",
    "un_countries_list\n",
    "\n",
    "# We are droping 2019 data as there are too many null values in the source for this year\n",
    "years_cols = ['1990', '1995', '2000', '2005']\n",
    "years_cols.extend([str(year) for year in range(2010, 2019)])\n",
    "cols_to_keep = ['Country']\n",
    "cols_to_keep.extend(years_cols)\n",
    "\n",
    "# We are going to read all the education files and put them in the same dataframe\n",
    "df_edu = pd.DataFrame(columns=['country', 'year', 'value', 'metric'])\n",
    "\n",
    "# For that, we will need the file names\n",
    "import os\n",
    "edu_file_names = os.listdir('../Datasets\\education_data_fragmented')\n",
    "edu_folder_path = r'../Datasets\\education_data_fragmented\\\\'\n",
    "\n",
    "for file_name in edu_file_names:\n",
    "\n",
    "    file_path = edu_folder_path + file_name\n",
    "\n",
    "    df_temp = pd.read_csv(\n",
    "        file_path, na_values='..', skiprows = 6,\n",
    "        usecols=cols_to_keep, encoding='latin 1'\n",
    "        )\n",
    "    \n",
    "    df_temp['Country'] = df_temp['Country'].str.strip()\n",
    "    df_temp = df_temp[df_temp['Country'].isin(un_countries_list)]\n",
    "\n",
    "    df_temp = df_temp.melt(id_vars='Country', value_vars=df_temp.columns[1:], var_name='year', value_name='value')\n",
    "    df_temp.columns = ['country', 'year', 'value'] # Keeping capitalization consistent\n",
    "    df_temp['metric'] = file_name[:-4] # dropping '.csv' from the name\n",
    "    df_edu = df_edu.append(df_temp, ignore_index=True)\n",
    "\n",
    "\n",
    "df_edu = df_edu.merge(right=df_country_map[['iso_code', 'UN_Country']], left_on='country', right_on='UN_Country', how='left')\n",
    "df_edu.drop(axis=1, columns=['country', 'UN_Country'], inplace=True)\n",
    "df_edu = df_edu[~df_edu['value'].isna()].reset_index(drop=True)\n",
    "df_edu['year'] = df_edu['year'].astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_edu.to_csv('../Datasets\\education_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To avoid performance hits in Tableau when building the correlation Matrix, we are already joining both datasets here, keeping only country+year combinations that are present in both datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_correlation = df_energy.merge(df_edu, on=['iso_code', 'year'], how='inner', suffixes=('', '_drop'))\n",
    "df_correlation.to_csv('../Datasets\\correlation_dataset.csv')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "929d62977bf2d888c36311be9d0accb34e312f263bdc0e4da1ad618d3be921c5"
  },
  "kernelspec": {
   "display_name": "Python 3.7.9 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
